{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be841770-f5eb-4aa3-b6f4-64dd95271454",
   "metadata": {},
   "source": [
    "## Array Computation with Dynamic Compute - GeoContexts\n",
    "In previous notebooks we have explored the interactive visualization component of `Dynamic Compute`. Here we will dive into how and when we can extract the underlying pixel data associated with our `Mosaic` and `ImageStack` objects as `numpy ndarrays`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43316d33-adcb-431e-aba7-174c9e91a39f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import descarteslabs as dl\n",
    "import descarteslabs.dynamic_compute as dc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d15b347-d3a8-4b45-9cf6-2471597f94d3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Intro to GeoContexts \n",
    "Before we pull down any pixel data we must first define an area of interst (AOI) and several raster metadata parameters by which we organize our dataset. At Descartes Labs this is where the `GeoContext` comes into play--we have several operators to create and utilize `GeoContext` objects, which we will introduce in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61597e2-1ad9-4d00-8985-9c3a0dd1b55a",
   "metadata": {},
   "source": [
    "First, we'll define an interactive `map` as we have in other examples and an associated `sentinel-2:l2a` `Mosaic` and `ImageStack`. Here we will be returning to [Kossuth County, Iowa's Highest Corn Producing County](https://www.nass.usda.gov/Statistics_by_State/Iowa/Publications/County_Estimates/2021/IA-CtyEst-Corn-02-21.pdf)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86da6e4-71e6-4c61-8b7a-b00aa10d4091",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m = dc.map\n",
    "m.center = 43.197541, -94.221831\n",
    "m.zoom = 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e445d59-5053-4aef-86fa-3c000e4f6984",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic = dc.Mosaic.from_product_bands(\n",
    "    \"esa:sentinel-2:l2a:v1\",\n",
    "    \"nir red green\",\n",
    "    start_datetime=\"2022-06-01\",\n",
    "    end_datetime=\"2022-09-01\",\n",
    ")\n",
    "\n",
    "s2_stack = dc.ImageStack.from_product_bands(\n",
    "    \"esa:sentinel-2:l2a:v1\",\n",
    "    \"nir red green\",\n",
    "    start_datetime=\"2022-06-01\",\n",
    "    end_datetime=\"2022-09-01\",\n",
    ").filter(lambda x: x.cloud_fraction < 0.1)\n",
    "\n",
    "_ = s2_mosaic.visualize(\"FCC\", m, scales=[[0, 1], [0, 1], [0, 1]])\n",
    "_ = s2_stack.median(axis=\"images\").visualize(\n",
    "    \"FCC-Cloudfree\", m, scales=[[0, 1], [0, 1], [0, 1]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050fddbd-48a3-4e52-8b47-35419708f7a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71c2163a-daa2-4cc0-ada3-1b2b926186bd",
   "metadata": {},
   "source": [
    "### Interactive Map GeoContexts\n",
    "\n",
    "The simplest `GeoContext` object to retrieve is that of your interactive `map`. We can simply call `map.geocontext()` to retrieve the current viewport as a `GeoContext`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3d87a7-24a0-47a4-aee2-8dc811c05916",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geocontext = m.geocontext()\n",
    "type(geocontext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b41ef896-7f89-4e38-8377-83e4b3302ded",
   "metadata": {},
   "source": [
    "Note this `GeoContext`'s attributes, which may vary depending on the provenance of the particular object:\n",
    "* `crs`: EPSG code\n",
    "* `bounds`: bounding rectangle of the viewport\n",
    "* `bounds_crs`: EPSG code\n",
    "* `shape`: shape of the resulting array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c034b10-6452-4e89-9cb1-80460c9a3ddb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "geocontext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0198d6-a21f-4fc5-8710-fbfb8ff8ed70",
   "metadata": {},
   "source": [
    "### Putting the _Compute_ in Dynamic Compute\n",
    "Once we have _either_ a `Mosaic` or `ImageStack` _and_ a properly defined `GeoContext` we can now retrieve our pixel data as a `numpy array`.\n",
    "To do this we simply choose which bands we want to pull down and call `.compute(geocontext)`. Note the resulting data type is a `DotDict`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc35534c-ee2c-4e49-a888-37f2d90759df",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic_data = s2_mosaic.pick_bands(\"nir red green\").compute(geocontext)\n",
    "type(s2_mosaic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77abeb90-39ad-4129-9d2c-71b4125870d0",
   "metadata": {},
   "source": [
    "At this point we have _already retrieved the array we want_. We can access that data by calling `.ndarray` on our results. Note that if we have `shape` defined in our `GeoContext` that our resulting array's will be `(nbands, nx, ny)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "682fb5a3-23ce-48f9-b58e-c3d8974c58a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic_data.ndarray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d42b34-4769-4d87-9545-29ade016898d",
   "metadata": {},
   "source": [
    "And finally we can use `dl.utils.display` to plot our dataset as an RGB:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab2a0429-7213-427a-9cc3-3baca90df5d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.utils.display(s2_mosaic_data.ndarray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16132ce6-a962-4dd4-b85f-b95d1161de9e",
   "metadata": {},
   "source": [
    "We also have `properties` returned to us in our results dictionary, which we will return to later on:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be26faab-a699-49d2-a1cd-554d0ed0355a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_mosaic_data.properties"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9746b966-f5ac-49a9-b56b-a9086961607b",
   "metadata": {},
   "source": [
    "We note there is some pesky cloud and cloud shadows present in our scene, but also recall that we have the _temporal dimension_ exposed to us through our `ImageStack`. We can also pull down that _entire stack of data_ through calling `ImageStack.compute(geocontext)`. Note the resulting array's shape here will be `(nsamples, nbands, nx, ny)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec3d11e-b14a-4599-94d4-ce4f709fd7fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s2_stack_data = s2_stack.pick_bands(\"nir red green\").compute(geocontext)\n",
    "s2_stack_data.ndarray.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b4951e-a81c-464a-ae7c-070bfed0599d",
   "metadata": {},
   "source": [
    "Here we will return to our `properties`, where the metadata is much more useful than in our previous `Mosaic` example. We can retrieve each Image's date through inline list comprehension:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b12da-9dac-4686-b55e-5635e6f25f44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "props = s2_stack_data.properties\n",
    "dates = [p[\"acquired\"].strftime(\"%Y-%m-%d %HH-%MM-%SS\") for p in props]\n",
    "dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5539ce-dee7-444f-b070-e9aa6d56fc1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ids = [p[\"id\"] for p in props]\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df98d0-7e63-4b80-864d-faddad050793",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "titles = [f\"{ids[i]} \\n {dates[i]}\" for i in range(len(dates))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bb26196-8d18-46c0-8e5b-d1ed804af5b9",
   "metadata": {},
   "source": [
    "### Pulling it All Together - ImageStacks\n",
    "Note here that each Image we retrieved in this stack _may not completely cover our input AOI_, that is because we have found an area _on the boundary between Sentinel-2 Imagery collections_. In the below plot we label each image with it's associated collectoin time as well as it's unique Image ID: (This may be a bit too much??)\n",
    "\n",
    "Note here that not each indvidual image covers the entire input AOI, this is because we are plotting individual Sentinel-2 strips!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0587257a-ee2f-458e-bc18-48602b84c43e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dl.utils.display(*s2_stack_data.ndarray, title=titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10cabe3d-79c7-449a-b669-8eb275b946f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5a1cf94-9cca-439a-92a0-66229278f75c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
